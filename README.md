# ü§ñ Copy of Aula 1 | Perceptron de m√∫ltiplas camadas



<details>

<summary><span data-gb-custom-inline data-tag="emoji" data-code="1f5c3">üóÉÔ∏è</span> Arquivos de Aula</summary>

:file\_cabinet: [**Reposit√≥rio**](https://github.com/camimq/deep\_learning\_and\_unstructured\_data)

:notebook\_with\_decorative\_cover: [**Conte√∫do**](https://drive.google.com/file/d/13\_4FySHDx-OyN7QBFRU64zmA1uw8S9W7/view?usp=sharing)

</details>

## Entendendo o neur√¥nio Perceptron

<figure><img src=".gitbook/assets/f6.webp" alt=""><figcaption><p>Imagem proposta por Frank Rosenblatt, para explicar o comportamento no neur√¥nio Perceptron</p></figcaption></figure>

**Passo a passo:**

1. **Sinais de Entrada (x1, x2)**:
   * S√£o os dados que alimentam a rede neural. No exemplo, temos dois sinais de entrada: ( x1 ) e ( x2 ).\

2. **Pesos Sin√°pticos (W1, W2)**:
   * Cada entrada √© multiplicada por um peso sin√°ptico. Esses pesos determinam a import√¢ncia de cada entrada. No exemplo, temos ( W1 ) e ( W2 ).\

3. **Combina√ß√£o Linear**:
   * As entradas ponderadas s√£o somadas junto com um valor de bias (B). A f√≥rmula √©: \[ y = x1 \cdot W1 + x2 \cdot W2 + B ]
   * O bias ajusta a resposta do neur√¥nio, permitindo que o modelo se ajuste melhor aos dados.\

4. **Fun√ß√£o de Ativa√ß√£o**:
   * A soma ponderada passa por uma fun√ß√£o de ativa√ß√£o, que decide se o neur√¥nio deve ser ativado ou n√£o. A fun√ß√£o de ativa√ß√£o pode ser, por exemplo, a fun√ß√£o sigmoide, ReLU, entre outras.\

5. **Sa√≠da (Output)**:
   * Se o valor ap√≥s a fun√ß√£o de ativa√ß√£o ultrapassar um certo limiar (threshold), o neur√¥nio √© ativado e gera uma sa√≠da.

#### Explica√ß√£o Did√°tica das F√≥rmulas:

* **Combina√ß√£o Linear**: \[ y = x1 \cdot W1 + x2 \cdot W2 + B ]
  * **x1, x2**: Entradas da rede.
  * **W1, W2**: Pesos associados √†s entradas.
  * **B**: Bias, que ajusta a resposta do neur√¥nio.\

* **Fun√ß√£o de Ativa√ß√£o**:
  * Pode ser representada por v√°rias fun√ß√µes matem√°ticas, como a sigmoide: \[ \sigma(y) = \frac{1}{1 + e^{-y\}} ]
  * Ou a ReLU (Rectified Linear Unit): \[ \text{ReLU}(y) = \max(0, y) ]

***

Podemos listar algumas caracter√≠sticas desse modelo de Perceptron:

* O modelo possui um natureza **bin√°ria (0 e 1)**. Tanto os sinais de entrada, quanto a saida, s√£o valores bin√°rios. O Perceptron √© um **classificador linear (bin√°rio)**.
* Os **pesos** da rede neural podem ser **ajust√°veis**, inspirados em sinapses, podendo ser excitat√≥rias ou inibit√≥rias (positivos ou negativos).
* √â utilizado na **aprendizagem supervisionada** e pode ser usado para classificar os dados de entrada fornecidos.
* Classifica a entrada separada duas categorias com uma linha reta.

O Perceptron segue o modelo _**feed-foward**_. Nesse tipo de modelo, as entradas da rede s√£o enviadas para o neur√¥nio, em seguida s√£o processadas e resultam em uma sa√≠da. Um √∫nico Perceptron pode resolver problemas lineares, a quest√£o √© que os dados do mundo real **n√£o s√£o lineares**, fazendo com que esse tipo de neur√¥nio artificial n√£o seja muito √∫til para solucionar problemas n√£o lineares.

<figure><img src=".gitbook/assets/image.png" alt=""><figcaption></figcaption></figure>

### Redes Neurais Multicamadas

Podemos considerar as redes neurais multicamadas como um aprendizado supervisionado diferente do Perceptron. Uma rede neural multicamadas constr√≥i v√°rias camadas ocultas, modelando assim a correla√ß√£o (ou depend√™ncias) entre os dados de entrada com os de sa√≠da. O seu treinamento envolve o ajuste dos par√¢metros, ou pesos e bias do modelo, para minimizar o erro.

Basicamente, seu funcionamento consiste no algoritmo alimentar cada inst√¢ncia de treinamento para a rede calcular a sa√≠da de cada neur√¥nio em cada camada consecutiva. em seguida, ele **mede o erro de sa√≠da da rede** (isto √©, a diferen√ßa entre a sa√≠da desejada e a sa√≠da real da rede) e **calcula o quanto cada neur√¥nio contribuiu para o erro** de cada neur√¥nio de sa√≠da na √∫ltima camada oculta. Como pr√≥ximo passo, o modelo passa a medir a quantidade dessas contribui√ß√µes de erro provenientes de cada neur√¥nio na camada oculta anterior, e assim por diante, at√© o algoritmo alcan√ßar a camada de entrada. Esta passagem reversa (tamb√©m conhecida como **backpropagation**) mede a **efici√™ncia do gradiente de erro em todos os pesos de conex√£o da rede**.

<figure><img src=".gitbook/assets/image (1).png" alt=""><figcaption></figcaption></figure>

## Detalhamento do c√≥digo da aula

### Classificando diferentes tipos de sementes de ab√≥bora

As sementes de ab√≥bora s√£o frequentemente consumidas como confeitos em todo o mundo devido √† sua quantidade adequada de prote√≠nas, gorduras, carboidratos e teores minerais. A base de dados **"SementesAbobora.xlsx"** possui um estudo foi realizado nos dois tipos de sementes de ab√≥bora mais importantes e de qualidade, **‚Äú√úrg√ºp Sivrisi‚Äù** e **‚Äú√áer√ßevelik‚Äù**, geralmente cultivadas nas regi√µes de √úrg√ºp e Karaca√∂ren na Turquia.

Muitas esp√©cies de sementes t√™m semelhan√ßas visuais, o que torna a classifica√ß√£o manual dif√≠cil e sujeita a erros. Redes neurais podem ser treinadas para identificar padr√µes que n√£o s√£o facilmente percept√≠veis pelo olho humano, aumentando a precis√£o da classifica√ß√£o.

Imagine que foi proposto para voc√™ o desafio de criar uma **intelig√™ncia para identificar os tipos de sementes para ajudar a equipe de engenheiros e engenheiras Agr√≠colas**. Para trabalhar com a precis√£o dos resultados x complexidade das caracter√≠sticas de sementes, voc√™ optou em utilizar as **redes neurais multilayer perceptron**. Vamos para a aplica√ß√£o?

#### Features

* Per√≠metro
* Maior\_Eixo\_Comprimento
* Comprimento\_Eixo\_Menor
* √Årea\_Convexa
* Equiv\_Di√¢metro
* Excentricidade
* Solidez
* Extens√£o
* Redondeza
* Proporcao
* Compacidade

#### Target

Classes: ((A)√áer√ßevelik, (B)√úrg√ºp Sivrisi)

#### An√°lise de correla√ß√£o

````python
```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Class'] = le.fit_transform(df['Class'])
correlation_matrix = df.corr().round(2)

fig, ax = plt.subplots(figsize=(15,10))
sns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax)
```
````

ste trecho de c√≥digo realiza as seguintes opera√ß√µes no conjunto de dados armazedo no [`df`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html):

1. **Importa√ß√£o de M√≥dulos**: Importa o [`LabelEncoder`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) da biblioteca [`sklearn.preprocessing`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html), que √© usado para converter r√≥tulos de texto em valores num√©ricos discretos.\

2. **Codifica√ß√£o de R√≥tulos**: Utiliza o [`LabelEncoder`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) para transformar os r√≥tulos na coluna `'Class'` do DataFrame [`df`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) de strings (ou qualquer outro tipo de r√≥tulo textual) para valores inteiros. Isso √© √∫til para modelos de _machine learning_ que requerem entradas num√©ricas.\

3. **C√°lculo da Matriz de Correla√ß√£o**: Calcula a matriz de correla√ß√£o para todas as colunas num√©ricas do DataFrame [`df`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) usando o m√©todo `.corr()`. A matriz de correla√ß√£o √© arredondada para duas casas decimais com `.round(2)`. A matriz de correla√ß√£o mostra como as vari√°veis est√£o relacionadas entre si, com valores variando de -1 a 1, onde 1 significa correla√ß√£o perfeita positiva, -1 significa correla√ß√£o perfeita negativa, e 0 significa que n√£o h√° correla√ß√£o.\

4. **Visualiza√ß√£o da Matriz de Correla√ß√£o**: Cria uma visualiza√ß√£o da matriz de correla√ß√£o usando a biblioteca `matplotlib` (para criar a figura e os eixos) e a biblioteca `seaborn` (para criar um mapa de calor). O mapa de calor mostra a matriz de correla√ß√£o com:
   * Tamanho da figura ajustado para 15x10.
   * Anota√ß√µes ativadas para mostrar os valores de correla√ß√£o nas c√©lulas do mapa de calor.
   * Linhas de grade ([`linewidths=.5`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) para separar as c√©lulas.

<figure><img src=".gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>

#### Tratando a vari√°vel _target_

````python
```python
# Utilizadno Label Enconder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df.Class = le.fit_transform(df['Class'])
```
````

Este trecho de c√≥digo realiza a codifica√ß√£o de r√≥tulos (labels) de texto para valores num√©ricos na coluna `Class`  do DataFrame ([`df`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)`)` usando a classe [`LabelEncoder`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) da biblioteca [`sklearn.preprocessing`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html):

1. **Importa√ß√£o da Classe  `LabelEncoder`**: Importa a classe [`LabelEncoder`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) do m√≥dulo [`sklearn.preprocessing`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html), que √© uma ferramenta para converter r√≥tulos de texto em valores num√©ricos incrementais (0, 1, 2, ...).\

2. **Cria√ß√£o de uma Inst√¢ncia de `LabelEncoder`**: Cria um objeto [`le`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) que √© uma inst√¢ncia da classe [`LabelEncoder`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html).\

3. **Transforma√ß√£o dos R√≥tulos da Coluna `Class`**: Utiliza o m√©todo [`fit_transform`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) do objeto [`le`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) para ajustar o codificador aos r√≥tulos de texto na coluna `Class` do DataFrame ([`df`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) e, em seguida, transform√°-los em valores num√©ricos. O resultado dessa transforma√ß√£o substitui os valores originais da coluna `Class` no DataFrame ([`df`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)).

Essencialmente, este c√≥digo converte categorias textuais em valores num√©ricos, o que √© uma pr√°tica comum em machine learning para preparar dados categ√≥ricos para algoritmos que requerem entrada num√©rica.

#### Separando os dados

````python
```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)
```
````

Utiliza a biblioteca [`sklearn`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) para dividir um conjunto de dados em subconjuntos de treinamento e teste:&#x20;

1. **Importa√ß√£o da fun√ß√£o** [**`train_test_split`**](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): A primeira linha importa a fun√ß√£o [`train_test_split`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) do m√≥dulo [`model_selection`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) da biblioteca [`sklearn`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html). Esta fun√ß√£o √© usada para dividir arrays ou matrizes em subconjuntos aleat√≥rios de treinamento e teste.\

2. **Divis√£o dos dados**: A fun√ß√£o [`train_test_split`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) √© chamada com quatro argumentos: [`X`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html), [`y`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html), e [`test_size=0.20`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html).
   * [`X`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) representa as caracter√≠sticas ou vari√°veis independentes do conjunto de dados. √â uma matriz onde cada linha √© um exemplo e cada coluna √© uma caracter√≠stica.
   * [`y`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) representa as vari√°veis dependentes ou os r√≥tulos de cada exemplo no conjunto de dados. √â um vetor onde cada elemento √© o r√≥tulo correspondente a cada linha de [`X`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html).
   * [`test_size=0.20`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) indica que 20% do conjunto de dados deve ser reservado para o conjunto de teste, enquanto os 80% restantes ser√£o usados para treinamento.\

3. **Retorno dos subconjuntos**: A fun√ß√£o retorna quatro subconjuntos:
   * [`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): As caracter√≠sticas para o conjunto de treinamento.
   * [`X_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): As caracter√≠sticas para o conjunto de teste.
   * [`y_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Os r√≥tulos para o conjunto de treinamento.
   * [`y_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Os r√≥tulos para o conjunto de teste.

Esses subconjuntos s√£o usados para treinar modelos de machine learning com [`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) e [`y_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html), e depois testar a performance desses modelos usando [`X_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) e [`y_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html).

#### Pr√©-processamento dos dados

````python
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)
scaler.fit(X_test)
```
````

Este trecho de c√≥digo est√° realizando a padroniza√ß√£o (ou normaliza√ß√£o) das caracter√≠sticas (_features_) dos conjuntos de dados de treinamento ([`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) e teste ([`X_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) para um modelo de aprendizado de m√°quina. A padroniza√ß√£o √© um passo comum no pr√©-processamento de dados para modelos de aprendizado de m√°quina, especialmente para algoritmos que s√£o sens√≠veis √† escala das caracter√≠sticas, como redes neurais, SVMs, e regress√£o log√≠stica. **O processo envolve subtrair a m√©dia e dividir pelo desvio padr√£o para cada caracter√≠stica, de modo que as caracter√≠sticas resultantes tenham m√©dia 0 e desvio padr√£o 1.**

No entanto, h√° um erro na abordagem apresentada:

1. [`scaler.fit(X_train)`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Calcula a m√©dia e o desvio padr√£o de [`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) para serem usados na padroniza√ß√£o.\

2. [`scaler.fit(X_test)`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Este passo √© incorreto para o conjunto de teste. Em vez de ajustar o [`scaler`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) novamente com [`X_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html), deveria-se usar [`scaler.transform(X_test)`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) para aplicar a transforma√ß√£o calculada a partir de [`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) ao conjunto de teste. Isso garante que a padroniza√ß√£o do conjunto de teste seja feita com base nos par√¢metros (m√©dia e desvio padr√£o) do conjunto de treinamento, mantendo a consist√™ncia e evitando o vazamento de dados do conjunto de teste para o modelo.

````python
```python
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
```
````

Este trecho de c√≥digo est√° realizando a normaliza√ß√£o dos dados de treino ([`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) e de teste ([`X_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) para um modelo de aprendizado de m√°quina, utilizando um objeto [`scaler`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) previamente ajustado.  O m√©todo [`transform`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) do [`scaler`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) aplica a transforma√ß√£o de normaliza√ß√£o que foi aprendida com o conjunto de dados de treino (geralmente usando o m√©todo `fit` ou `fit_transform` do [`scaler`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) sobre [`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) aos dados de treino e de teste.

#### Construindo a arquitetura da rede neural multicamadas

````python
```python

# Semente aleat√≥tia para manter os mesmos dados
tf.random.set_seed(7)

# Definindo entradas da rede + tamanho da batch de processamento
input_shape = X_train.shape[1]    # Vari√°veis de entrada
output_shape = y_train.shape[1]   # Classe preditora
batch_size = 20

# Abrindo uma sequencia de neuronios
model = models.Sequential()

# input layer
# Entrada da rede
model.add(layers.Dense(
                        batch_size
                       ,input_shape=(input_shape,)
                       ,activation='relu'))

# hidden layer
# Camada oculta
model.add(layers.Dense(
                        12
                       ,activation='relu'))

# hidden layer
# Camada oculta
model.add(layers.Dense(
                        6
                       ,activation='relu'))


# dropout layer
# Aplicando regulariza√ß√£o
model.add(layers.Dropout(0.5))

# output layer
# Camada de sa√≠da
model.add(layers.Dense(
                        output_shape
                       ,activation='sigmoid'))

# Configurar o otimizador Adam com uma learning rate espec√≠fica
# Defina a learning rate desejada
learning_rate = 0.001
otimizador = Adam(learning_rate=learning_rate)

# Compilar o modelo com o otimizador configurado
model.compile(loss='binary_crossentropy', optimizer=otimizador, metrics=['accuracy'])

# summmary
model.summary()
```
````

Este trecho de c√≥digo est√° construindo e compilando um modelo de rede neural usando a biblioteca **TensorFlow**, especificamente com a **API Keras**:

1. **Definir uma semente aleat√≥ria**: Garante que os resultados sejam reproduz√≠veis ao inicializar os pesos da rede neural de forma aleat√≥ria.\

2. **Definir as dimens√µes de entrada e sa√≠da e o tamanho do lote**:
   * [`input_shape`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): N√∫mero de vari√°veis de entrada, determinado pela forma do conjunto de treinamento ([`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)).
   * [`output_shape`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): N√∫mero de classes de sa√≠da, determinado pela forma do conjunto de treinamento de sa√≠da ([`y_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)).
   * [`batch_size`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): N√∫mero de amostras a serem processadas antes de atualizar os pesos da rede.\

3. **Construir o modelo**:
   * **Camada de entrada**: Uma camada densa com ativa√ß√£o ReLU. O n√∫mero de neur√¥nios √© igual ao [`batch_size`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html), e a forma de entrada corresponde ao n√∫mero de vari√°veis de entrada.
   * **Camadas ocultas**: Duas camadas densas com 12 e 6 neur√¥nios, respectivamente, ambas com ativa√ß√£o ReLU.
   * **Camada de regulariza√ß√£o (Dropout)**: Uma camada de Dropout com taxa de 0.5 para reduzir o _overfitting_, desligando aleatoriamente 50% das conex√µes entre as camadas durante o treinamento.
   * **Camada de sa√≠da**: Uma camada densa com ativa√ß√£o **sigm√≥ide**, onde o n√∫mero de neur√¥nios corresponde ao n√∫mero de classes de sa√≠da ([`output_shape`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)). **A ativa√ß√£o sigm√≥ide √© usada para problemas de classifica√ß√£o bin√°ria**.\

4. **Compilar o modelo**:
   * **Otimizador**: Usa o **Adam** com uma taxa de aprendizado ([`learning_rate`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) de 0.001.
   * **Fun√ß√£o de perda**: `binary_crossentropy`, adequada para problemas de classifica√ß√£o bin√°ria.
   * **M√©tricas**: Avalia o modelo com base na sua precis√£o (`accuracy`).

Este modelo √© t√≠pico para tarefas de classifica√ß√£o, onde se tenta prever a qual classe uma determinada entrada pertence.

````python
```python
# Configurando as √©pocas de processamento para a converg√™ncia do erro da fun√ß√£o de custo
epoch = 100

hist = model.fit(X_train
                  ,y_train
                  ,epochs = epoch
                  ,batch_size=batch_size
                  ,shuffle=True
                  ,validation_data=(X_test, y_test)
                  ,verbose=0
                  ,callbacks=[TqdmCallback(verbose=0)]
          )
```
````

Este trecho de c√≥digo est√° treinando um modelo de rede neural (Perceptron Multicamadas) usando um conjunto de dados de treinamento:&#x20;

1. Define o n√∫mero de √©pocas ([`epoch = 100`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)), que √© o n√∫mero de vezes que o algoritmo de aprendizado passar√° por todo o conjunto de dados de treinamento.\

2. [`hist = model.fit(...)`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Inicia o treinamento do modelo. [`hist`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) armazenar√° o hist√≥rico do processo de treinamento, como a perda e as m√©tricas de avalia√ß√£o para cada √©poca.\

3. [`X_train, y_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Os dados de entrada ([`X_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) e as etiquetas/objetivos ([`y_train`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) usados para treinar o modelo.\

4. [`epochs=epoch`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Define o n√∫mero de √©pocas para o treinamento, usando o valor definido anteriormente.\

5. [`batch_size=batch_size`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Define o tamanho do lote para o treinamento. O tamanho do lote √© o n√∫mero de amostras processadas antes de o modelo ser atualizado.\

6. [`shuffle=True`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Embaralha os dados de treinamento antes de cada √©poca para evitar que o modelo aprenda a ordem dos dados.\

7. [`validation_data=(X_test, y_test)`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Define os dados de teste ([`X_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html), [`y_test`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)) usados para avaliar o modelo ap√≥s cada √©poca. Isso ajuda a monitorar o desempenho do modelo em dados n√£o vistos durante o treinamento.\

8. [`verbose=0`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Define o modo silencioso, o que significa que n√£o ser√£o impressas mensagens de progresso durante o treinamento.\

9. [`callbacks=[TqdmCallback(verbose=0)]`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html): Usa um _callback_ para personalizar o comportamento do treinamento. [`TqdmCallback`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) √© usado para fornecer uma barra de progresso personalizada, mas aqui est√° configurado para ser silencioso ([`verbose=0`](https://vscode-file/vscode-app/c:/Users/Elitebook/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)).

Em resumo, este c√≥digo configura e inicia o treinamento de um modelo de rede neural usando um conjunto de dados espec√≠fico, com v√°rias op√ß√µes para controlar o processo de treinamento, como o n√∫mero de √©pocas, o tamanho do lote, embaralhamento dos dados, dados de valida√ß√£o, e configura√ß√µes de verbosidade e _callbacks_.

## Resumo Geral da Aula

Nesta aula, foi abordado o tema do Perceptron de M√∫ltiplas Camadas, que √© uma arquitetura muito utilizada em redes neurais artificiais. Foi explicado como funciona um neur√¥nio artificial e como o Perceptron realiza a classifica√ß√£o bin√°ria linear. Tamb√©m foi introduzido o conceito de redes neurais multicamadas, que s√£o capazes de lidar com tarefas mais complexas e modelar a correla√ß√£o entre os dados de entrada e sa√≠da. O processo de treinamento dessas redes foi abordado, destacando-se o modelo de retropropaga√ß√£o. Al√©m disso, foram apresentados os hiperpar√¢metros das redes neurais multicamadas, como o n√∫mero de camadas ocultas, o n√∫mero de neur√¥nios e as fun√ß√µes de ativa√ß√£o. A import√¢ncia da escala dos dados e a regulariza√ß√£o foram discutidas como formas de evitar problemas como o overfitting. Foram mencionadas algumas bibliotecas populares para redes neurais em Python, como TensorFlow, Keras e PyTorch. No geral, a aula forneceu uma vis√£o geral sobre as redes neurais artificiais e como elas podem ser aplicadas em problemas de aprendizado de m√°quina.

